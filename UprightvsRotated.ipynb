{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xing Xiang's Upright vs Rotated classifer for Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to classify between homework images that are upright and rotated, either 90 degrees cw/ccw.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 24,128,834\n",
      "Trainable params: 541,122\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First, I construct the model architecture and make use of ResNet50, and leave only the last layer trainable.\n",
    "# Number of classes is 2. Either upright or rotated.\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg'))\n",
    "my_new_model.add(Dense(256, activation='relu'))\n",
    "my_new_model.add(Dropout(rate=0.5))\n",
    "my_new_model.add(Dense(64, activation='relu'))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# Indicate whether the first layer should be trained/changed or not.\n",
    "my_new_model.layers[0].trainable = False\n",
    "\n",
    "my_new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "my_new_model.compile(optimizer=SGD(learning_rate=0.003, momentum=0.9, nesterov=True, name='SGD'), \n",
    "                     loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1050 images belonging to 2 classes.\n",
      "Found 144 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# use image generators to load my images sourced from google images. I added data augmentation for the train generator only \n",
    "# to increase the number of train data.\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 100\n",
    "data_generator = ImageDataGenerator(preprocess_input,  width_shift_range=0.4,\n",
    "    height_shift_range=0.4, zoom_range=0.4, horizontal_flip=True)\n",
    "\n",
    "# normal_generator = ImageDataGenerator(preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "                                        directory=\"./train\",\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=100,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "                                        directory=\"./test\",\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=10,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# make use of callbacks to stop early upon sign of overtraining, and also to save weights\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "earlystopping_callback = EarlyStopping(monitor='val_loss', patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xx\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "35/35 [==============================] - 12s 340ms/step - loss: 0.5486 - accuracy: 0.7146 - val_loss: 0.3987 - val_accuracy: 0.7828\n",
      "Epoch 2/25\n",
      "35/35 [==============================] - 10s 280ms/step - loss: 0.3688 - accuracy: 0.8391 - val_loss: 0.2846 - val_accuracy: 0.8487\n",
      "Epoch 3/25\n",
      "35/35 [==============================] - 10s 286ms/step - loss: 0.2971 - accuracy: 0.8773 - val_loss: 0.3077 - val_accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "# Using training data to fit my model and validate against validation data\n",
    "\n",
    "fit_stats = my_new_model.fit(x=train_generator, validation_data=validation_generator, steps_per_epoch=35, validation_steps=25 ,epochs=25, verbose=1, callbacks=[earlystopping_callback,checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5485996603965759, 0.36879879236221313, 0.29712092876434326],\n",
       " 'accuracy': [0.7146268486976624, 0.8391044735908508, 0.8773134350776672],\n",
       " 'val_loss': [0.39867883920669556, 0.2846055030822754, 0.3077290952205658],\n",
       " 'val_accuracy': [0.7827869057655334, 0.848739504814148, 0.8781512379646301]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_stats.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to prepare test images easily\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def prepare_img(filePath):\n",
    "    out = np.array(Image.open(filePath))\n",
    "    out = out.reshape((-1, 100, 100, 3))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/144 --> Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Test out model with a folder of test images\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Getting class labels\n",
    "labels = (validation_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "# print(labels)\n",
    "\n",
    "num_correct = 0\n",
    "num_total = 0\n",
    "for filePath in Path(r\"C:\\Users\\xx\\Workspace\\Deep learning tryouts\\test\").glob(\"**/*.jpg\"):\n",
    "    num_total += 1\n",
    "    \n",
    "    # use model to predict class\n",
    "    pred = my_new_model.predict(prepare_img(filePath))\n",
    "    \n",
    "    predicted_idx = np.argmax(pred,axis=1)[0]\n",
    "    predicted_class = labels[predicted_idx]\n",
    "#     print(f\"Label-{filePath.parent.stem}, predicted-{predicted_class}\") \n",
    "    \n",
    "    if filePath.parent.stem == predicted_class:\n",
    "        num_correct += 1\n",
    "        \n",
    "    \n",
    "accuracy = round(num_correct / num_total, 2) \n",
    "print(f\"{num_correct}/{num_total} --> Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.7.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
